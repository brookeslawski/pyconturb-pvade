{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constrained turbulence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a demonstration of how the `pyconturb` package can be easily used to generate turbulence that is constrained by one or more time series at a point in space.\n",
    "\n",
    "The demo uses pre-generated time series that were simulated at a series of vertically spaced points. The `gen_turb` function is then used with these time series as constraints to result in a turbulence box that follows IEC 61400-1 Ed. 3 specifications but is correlated with the constraints. In other words, the coherence between the constraining time series and the simulated time series also follow IEC specifications.\n",
    "\n",
    "It is worth noting that other models for the spectral magnitudes or coherences can be used. This demo is only meant as a proof-of-concept.\n",
    "\n",
    "\n",
    "This example has the following sections:  \n",
    "\n",
    "* [Preliminaries](#Preliminaries:-importing-functions)  \n",
    "\n",
    "* [Constraining time series](#Constraining-time-series)  \n",
    "\n",
    "* [Inputs to constrained turbulence](#Inputs-to-constrained-turbulence)  \n",
    "\n",
    "* [Generate constrained turbulence](#Generate-constrained-turbulence)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries: importing functions\n",
    "\n",
    "We first set a few notebook-specific functions/variables and then import functions from the `pyconturb` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt  # matplotlib for some plotting\n",
    "import numpy as np  # numeric python functions\n",
    "import pandas as pd  # need this to load our data from the csv files\n",
    "\n",
    "from pyconturb.simulation import gen_turb  # generate turbulence function\n",
    "from pyconturb._utils import gen_spat_grid  # useful helper function\n",
    "\n",
    "data_dir = os.path.join(os.path.abspath('.'), 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraining time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us first load the spatial and turbulence dataframes of the constraining data to get an idea of what constraints will be present. We can also do some basic visualization to get a better idea of what these constraining time series look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_spat_path = os.path.join(data_dir, 'conturb_spat.csv')  # path to spat csv\n",
    "con_spat_df = pd.read_csv(con_spat_path)  # spatial info\n",
    "con_turb_path = os.path.join(data_dir, 'conturb.csv')  # path to saved constrain turbulence\n",
    "con_turb_df = pd.read_csv(con_turb_path).set_index('time')  # turbulence\n",
    "dt = con_turb_df.index[1]  # get sample time from constr\n",
    "T = con_turb_df.index[-1] + dt  # get length of sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how these spatial and turbulence dataframes for the constraining data need to be structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_spat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_turb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that the format of these dataframes are very similar to what we saw in the unconstrained example. In particular, the spatial dataframe has 5 columns (turbulence component, point identifier and spatial location) and the turbulence dataframe has columns corresponding to the turbulence component/point ID and rows that correspond to the time step.\n",
    "\n",
    "We can plot the points to visualize the locations of the constrainting points in space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spat_pts = con_spat_df[['p_id', 'y', 'z']].drop_duplicates()\n",
    "[plt.scatter(spat_pts.loc[i, 'y'], spat_pts.loc[i, 'z'],\n",
    "             label=f'p{spat_pts.loc[i, \"p_id\"]}') for i in spat_pts.index]\n",
    "plt.legend(); plt.ylabel('height [m]'); plt.xticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is apparant that the constraining time series are located at a series of vertical heights, exactly as we would have if we were using met mast data. Additionally, the numbering goes from `p0` at the lowest height to `p5` at the highest.\n",
    "\n",
    "Now let's visualize the constraining time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = con_turb_df.filter(regex='u_', axis=1).plot(lw=0.75)  # subselect long. wind component\n",
    "ax.set_ylabel('longitudinal wind speed [m/s]');\n",
    "[print(x) for x in con_turb_df.filter(regex='u_', axis=1).mean()];  # print mean values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an increase in the mean wind speed for higher points, which is as expected.\n",
    "\n",
    "Now, let's simulate a turbulence box.\n",
    "\n",
    "## Inputs to constrained turbulence\n",
    "\n",
    "The first step is to define the spatial information for the desired turbulence box and the related parameters for the turbulence generation technique. In this case we will use the default IEC 61400-1 Ed. 3 simulation procedures (Kaimal Spectrum with Exponential Coherence). By default it will utilize the mean wind speed profile from IEC 61400-1 Ed. 3, which is a power law with an exponent of 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.linspace(-10, 10, 5)  # lateral components of turbulent grid\n",
    "z = np.linspace(35, 115, 9)  # vertical components of turbulent grid\n",
    "kwargs = {'u_hub': 10, 'turb_class': 'B', 'z_hub': 75,  # necessary keyword arguments for IEC turbulence\n",
    "          'T': T, 'dt': dt}  # simulation length (s) and time step (s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function below generates the actual spatial data. It assumes we want all three turbulence components at each spatial location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spat_df = gen_spat_grid(y, z)  # create our spatial pandas dataframe. Columns are k, p_id x, y, and z."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate constrained turbulence\n",
    "\n",
    "The actual constrained turbulence generation is now just a one-line function. Note that the `scale=True` option scales the theoretical magnitudes before correlation to prevent and loss/gain of spectral energy due to the discretization of the theoretical spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data = {'con_spat_df': con_spat_df,\n",
    "            'con_turb_df': con_turb_df}  # assemble spatial and time of constraints\n",
    "sim_turb_df = gen_turb(spat_df, con_data=con_data, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the result easily because it is a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim_turb_df.filter(regex='_p0', axis=1).plot();  # just p0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can check out statistics of $u$ by height:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = sim_turb_df.filter(regex='u_', axis=1).describe().loc[['mean', 'std']]\n",
    "# plot\n",
    "plt.clf(); plt.subplot(1, 2, 1);\n",
    "plt.scatter(stats.loc['mean'], spat_df[spat_df.k==0].z.values, label='Mean profile')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(stats.loc['std'], spat_df[spat_df.k==0].z.values, label='Std dev')\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
